Loading cineca-ai/4.3.0
  Loading requirement: cuda/12.1 nccl/2.19.1-1--gcc--12.2.0-cuda-12.1
    cudnn/8.9.7.29-12--gcc--12.2.0-cuda-12.1 gcc/12.2.0-binut2.41
    openmpi/4.1.6--gcc--12.2.0 bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv python/3.11.6--gcc--8.5.0 cmake/3.27.7
    openjdk/11.0.20.1_1
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
Temporal window: T=16, stride=4
[INFO] rank 0/16 device=cuda:0
[INFO] batch_size per GPU=128 (global=2048)
[INFO] lr scaled from 0.0005 to 0.008 for world_size=16
Logging metrics to outputs/runs/exp_x3dm_heatmapfocal_2/training_log.csv
[Epoch 1] train: L=0.1176 (hm=0.1176, pr=0.8887, peak=-0.0755)
[Epoch 1] elapsed: 79.3s
[Epoch 2] train: L=0.0121 (hm=0.0121, pr=0.7823, peak=-1.3744)
[Epoch 2] elapsed: 45.1s
[Epoch 3] train: L=0.0091 (hm=0.0091, pr=0.7492, peak=-1.2022)
[Epoch 3] elapsed: 45.2s
[Epoch 4] train: L=0.0076 (hm=0.0076, pr=0.7472, peak=-1.2057)
[Epoch 4] elapsed: 43.4s
[Epoch 5] train: L=0.0069 (hm=0.0069, pr=0.7525, peak=-1.2358)
[Epoch 5] elapsed: 47.0s
[Epoch 6] train: L=0.0064 (hm=0.0064, pr=0.7378, peak=-1.1932)
[Epoch 6] elapsed: 47.1s
